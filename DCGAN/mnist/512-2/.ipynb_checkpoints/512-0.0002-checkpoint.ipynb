{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jE7iIVUsuAIJ"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import utils, datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Wn86oROulHT",
    "outputId": "3cf957cc-0f76-406e-b093-71a5b59ef68c"
   },
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DQfcwQVxunnm"
   },
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "dataroot = \"data2/mnist\"\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 10\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 512\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this size using a transformer.\n",
    "image_size = 64\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 1\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 30\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6yg1vbgduq1S",
    "outputId": "c79e6c0b-e9f1-46e6-df2c-fcb855fc5332"
   },
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root=dataroot,\n",
    "    train=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ]),\n",
    "    download=True\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root=dataroot,\n",
    "    train=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    ")\n",
    "dataset = train_data+test_data\n",
    "print(f'Total Size of Dataset: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2PpQ4sLuu1r"
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZkA5y27xuxZg"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if (torch.cuda.is_available() and ngpu > 0) else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 846
    },
    "id": "EnxbuxaBuzxo",
    "outputId": "b2aabee9-e7f4-4978-d292-c06551daa784"
   },
   "outputs": [],
   "source": [
    "inputs = next(iter(dataloader))[0]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Training Images\")\n",
    "plt.axis('off')\n",
    "inputs = utils.make_grid(inputs[:100]*0.5+0.5, nrow=10)\n",
    "plt.imshow(inputs.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NskYWaFou2mL"
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L8pKzme7u4XO"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WzyaWgXLu6OT",
    "outputId": "15510f73-2130-44be-f4ba-36b78e85222d"
   },
   "outputs": [],
   "source": [
    "# Create the generator\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if device.type == 'cuda' and ngpu > 1:\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights to mean=0, stdev=0.2.\n",
    "netG.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GkrH0h1Iu78E"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            # state size. (1) x 1 x 1\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GD01rpvju-BU",
    "outputId": "1b73a9e3-65a1-4972-b526-787b7bcb5154"
   },
   "outputs": [],
   "source": [
    "# Create the Discriminator\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if device.type == 'cuda' and ngpu > 1:\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights to mean=0, stdev=0.2.\n",
    "netD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sNTuhNQhu_iL"
   },
   "outputs": [],
   "source": [
    "# Initialize BCELoss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize the progression of the generator\n",
    "fixed_noise = torch.randn(100, nz, 1, 1, device=device)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = torch.optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = torch.optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKC2_kn9vDos",
    "outputId": "d9aab52f-ae32-453d-d591-572c0037f818"
   },
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "D_x_list = []\n",
    "D_z_list = []\n",
    "loss_tep = 10\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    beg_time = time.time()\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(dataloader):\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        # Format batch\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_cpu).view(-1)\n",
    "\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Add the gradients from the all-real and all-fake batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = netD(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "        end_time = time.time()\n",
    "        run_time = round(end_time-beg_time)\n",
    "        if (i + 1) % 10 == 0:\n",
    "          print(\n",
    "              f'Epoch: [{epoch+1:0>{len(str(num_epochs))}}/{num_epochs}]',\n",
    "              f'Step: [{i+1:0>{len(str(len(dataloader)))}}/{len(dataloader)}]',\n",
    "              f'Loss-D: {errD.item():.4f}',\n",
    "              f'Loss-G: {errG.item():.4f}',\n",
    "              f'D(x): {D_x:.4f}',\n",
    "              f'D(G(z)): [{D_G_z1:.4f}/{D_G_z2:.4f}]',\n",
    "              f'Time: {run_time}s',\n",
    "              end='\\r'\n",
    "          )\n",
    "        with open('output.txt', 'a') as f:\n",
    "          f.write(\n",
    "              f'Epoch: [{epoch+1:0>{len(str(num_epochs))}}/{num_epochs}] ' +\n",
    "              f'Step: [{i+1:0>{len(str(len(dataloader)))}}/{len(dataloader)}] ' +\n",
    "              f'Loss-D: {errD.item():.4f} ' +\n",
    "              f'Loss-G: {errG.item():.4f} ' +\n",
    "              f'D(x): {D_x:.4f} ' +\n",
    "              f'D(G(z)): [{D_G_z1:.4f}/{D_G_z2:.4f}] ' +\n",
    "              f'Time: {run_time}s\\n'\n",
    "          )\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # Save D(X) and D(G(z)) for plotting later\n",
    "        D_x_list.append(D_x)\n",
    "        D_z_list.append(D_G_z2)\n",
    "\n",
    "        # Save the Best Model\n",
    "        if errG < loss_tep:\n",
    "            torch.save(netG.state_dict(), 'model.pt')\n",
    "            loss_tep = errG\n",
    "\n",
    "    # Check how the generator is doing by saving G's output on fixed_noise\n",
    "    with torch.no_grad():\n",
    "        fake = netG(fixed_noise).detach().cpu()\n",
    "    img_list.append(utils.make_grid(fake*0.5+0.5, nrow=10))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "id": "DeZRoC9mvFp2",
    "outputId": "2d748d5f-5188-4025-de37-e5b2ae44cb8d"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses, label=\"G\")\n",
    "plt.plot(D_losses, label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.axhline(y=0, label=\"0\", c=\"g\") # asymptote\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "7IFZuWJMvIwi",
    "outputId": "b1d92524-7125-4604-b038-8d445f39929d"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"D(x) and D(G(z)) During Training\")\n",
    "plt.plot(D_x_list, label=\"D(x)\")\n",
    "plt.plot(D_z_list, label=\"D(G(z))\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.axhline(y=0.5, label=\"0.5\", c=\"g\") # asymptote\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jRdAxDkVvKk7",
    "outputId": "1166b1d8-41d3-4e29-ca12-06c146e5b0e2"
   },
   "outputs": [],
   "source": [
    "# 保存每帧图像到 \"pic\" 文件夹\n",
    "for i, frame in enumerate(img_list):\n",
    "    plt.imshow(frame.permute(1, 2, 0))\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"512-2/pic/frame_{i}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "id": "suAGREI-vM35",
    "outputId": "2711f94b-6944-4a01-b536-fe76dc143508",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Size of the Figure\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "# Plot the real images\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "real = next(iter(dataloader))\n",
    "plt.imshow(utils.make_grid(real[0][:100]*0.5+0.5, nrow=10).permute(1, 2, 0))\n",
    "\n",
    "# Load the Best Generative Model\n",
    "netG = Generator(0)\n",
    "netG.load_state_dict(torch.load('model.pt', map_location=torch.device('cpu')))\n",
    "netG.eval()\n",
    "\n",
    "# Generate the Fake Images\n",
    "with torch.no_grad():\n",
    "    fake = netG(fixed_noise.cpu())\n",
    "\n",
    "# Plot the fake images\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "fake = utils.make_grid(fake*0.5+0.5, nrow=10)\n",
    "plt.imshow(fake.permute(1, 2, 0))\n",
    "\n",
    "# Save the comparation result\n",
    "plt.savefig('result.jpg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "def zip_folder(folder_path, zip_filename):\n",
    "    # 创建一个Zip文件对象\n",
    "    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        # 遍历文件夹内的所有文件并添加到Zip文件\n",
    "        for foldername, subfolders, filenames in os.walk(folder_path):\n",
    "            for filename in filenames:\n",
    "                file_path = os.path.join(foldername, filename)\n",
    "                zipf.write(file_path, os.path.relpath(file_path, folder_path))\n",
    "\n",
    "# 调用函数，压缩文件夹\n",
    "folder_to_compress = 'pic'  # 替换为你的文件夹路径\n",
    "zip_filename = 'pic.zip'  # 替换为你的压缩文件名\n",
    "\n",
    "zip_folder(folder_to_compress, zip_filename)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
